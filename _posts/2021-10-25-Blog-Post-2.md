Do you want to learn to scrape?\
Well you've come to an okay place to learn.\
Welcome to scraping_airlines. \
\
We're gonna be using the scrapy package for python to scrape IMDB today, so make sure you have that installed.\
Here's a link to the github repository of the scraper we're going to be recreating today: \
https://github.com/Nour110/easyscrape \
You should see a file called IMDB_scraper, within that file there are many other. Find the folder called spiders and open it. Then open imdb_spider.py. This is our scraper. Looks simple right? There aren't many lines of code.\
\
Let us begin creating our scraping project. Notice the seatbelt light is on, so buckle up.

## Creating a new scraper ##
Okay, make a new folder on your computer. for the sake of simplicity, say you make a new folder called `scraping_airlines` on your desktop.\
Now open command prompt (or the anaconda prompt). Navigate to you new folder and type the following commands in order:



```python
scrapy startproject IMDB_scraper
cd IMDB_scraper
```

This will create many files, files that look similar to the files you saw before if you looked through the github link. You won't need to really mess with many of them, in fact, you can keep them all as they are.\
Now inside the `spiders` folder that was just created. Create a file `imdb_spider.py`. Open this file and we're gonna start writing some code.
Or more accurately, you're gonna copy and paste the following:


```python
# to run 
# scrapy crawl imdb_spider -o results.csv
import scrapy
from scrapy.http import Request

class ImdbSpider(scrapy.Spider):
    name = 'imdb_spider'
    
    allowed_domains = [
        "imdb.com"
    ]
    
    start_urls = ['https://www.imdb.com/title/tt0098800/']
```

Note a few things.\
We've created a new class and its inheriting from the `scrapy.Spider` class. Cool right? Well with inheritance comes responsibility.\
First, we have to give our spider a name using the `name` parameter, this is very specific so don't misspell `name`. The name you give will be used to run the spider later. See how in the comments it says you need to run the command\
`scrapy crawl imdb_spider -o results.csv`\
If you changed the name of the spider then you would have to also adjust the command to reflect that.\
\
Also, notice the parameter `start_urls`, and again know that you must provide something for `start_urls` and it should indeed be a list of strings which are the urls of webpages. This determines the page that your scraper is gonna start at, you could provide several urls as well.\
\
For our scraper, please take a moment and think of your favorite tv show or movie. I chose The Fresh Prince of Bel-Air as you'll note if you follow the link I provided in start_urls. Now take go to your favorite tv show or movie's imdb page and copy and paste its url in place of my url. Remember that it should be saved as a string.\

## The basics of Scrapy ##

Now please go back to the command prompt. Let `URL` = the imdb url of your favorite tv show or movie.\
Type the following into the command prompt\
``scrapy shell URL``\
You are now crawling the webpage of your favorite tv show/ movie's imdb page.\
Exciting isn't it?\
The scrapy shell is a good way to experiment and figure out how to pull information from a webpage or just get a grip on how scrapy actual works.\
\
Okay back to `imdb_spider.py` just for a quick second!\
Add the following function to your `ImdbSpider` class\
`def parse(self,response)`\
\
Now ask yourself, what is response and how do I figure it out? I can't run anything on this stupid text editor!\
\
Oh wait! There's that neato tool scrapy shell, maybe that'll help. Indeed it will.\
\
Let's go to the scrapy shell and just type\
`response`\
Oh well would you look at that! It looks like our url but not quite. In fact if you wanted to extract the url, you would just type `response.url`. If you were to add `print(response.url)` to the parse method then when you ran the spider it would print out the url. So you can see that the scrapy shell is very useful in experimenting with our code without having to run the whole scraper every time.\
\
Last little basic idea tool. Go to your chosen imdb page and use your browser's tool to inspect the html code of the page. If you're on windows 10 using google chrome, just hit the F12 key.\
\
You can actually extract parts of the webpage with scrapy using the css selectors of the page. If this is gibberish to you then thats okay. Let's do a little example.\
\
Notice on the page that there should be a small description of the show/movie under the image and trailer and above the `Creators` section. Now using your inspector tool, look for a little icon at the top left corner that looks like a box with a cursor hovering over it. (Might be different if you're using a different browser/operating system). It's a tool so that you can zoom in on the individual html code of a given element. With that tool activated click on the description.\
You should see that the following html line has been highlighted or a line very similar to this if your favorite tv show isn't The Fresh Prince of Bel-Air\
`<span role="presentation" data-testid="plot-l" class="GenresAndPlot__TextContainerBreakpointL-cum89p-1 gwuUFD">â€¦</span>`\
\
If you double click the three dots `>...<` then you should see the same text as the description.\
\
How can we possibly extract this data using scrapy?\
\
Scrapy has a very useful method to navigate the wepage by querying the css elements.
To use it you'll type\
`response.css(QUERY)`
where query is the css query you want to execute.\
\
If you want to learn how css queries work, I highly recommend playing this game:\
https://flukeout.github.io/ \
Completing this game will probably allow you to follow whats to come much more easily.\
\
See if you can figure how to at least reach the line we want using the scrapy shell. Note that the css query has to be a string so enclose your query in quotations!\
\
Let's work through it together.\
\
Looking at the html of the page, we can try to query for the tag `span` which has an attribute `role = "presentation"`\
To do this we'll type:\
`response.css('span[role="presentation"]')`\ 
in our scrapy shell.\
This gives us a decently long list of `scrapy.selector.unified.Selector` objects.\
\
If you look at each one of those objects, they hold the data of each of the tags. You could look for the tag we're looking for in the list and just count which index it would be but that would be time consuming so let's try a different query and try to get just one object.\
\
Looking at the html of the page again, we see that the `span` tag we want is actually the child of \
`<p data-testid="plot" class="GenresAndPlot__Plot-cum89p-6 bUyrda">`\
So, maybe we can narrow the search down. `"plot"` seems quite specific to me so I have high hopes for this.\
\
Let's try\
`response.css('p[data-testid="plot"]')`\
Would you look at that, a single element.\
`[<Selector xpath="descendant-or-self::p[@data-testid = 'plot']" data='<p data-testid="plot" class="GenresAn...'>]`\
\
This should make our job much easier. So lets save this to a variable called `useful` in our shell just by running\
`useful = response.css('p[data-testid="plot"]')`\
To put it simply `response.css('p[data-testid="plot"]')` will yield a subset of the html code of the page, namely, it'll contain the line we saw above with the `p` tag and its children and nothing else. We can navigate it using the same `.css` method. So, lets try to get to our text!\
\
Looking at the html, we see that there are three children with `span` tag and the attribute `role = "presentation"`. We want the second one. There's a few ways to reach it. We'll do the following:\
`plot_html = useful.css('span[data-testid="plot-l"]')`\
Almost there! One more line of code. To get the text portion of `plot_html` simply type the following\
`plot_htlml.css('::text')`\
Nope, missing one last thing\
`plot_html.css('::text').get()`
And there you go, you have now extracted the description of your favorite tv show/movie.\
Say, you wanted to save this to a csv file with the name of the your given show.\
Then you would write the following spider


```python
# to run 
# scrapy crawl tutorial_imdb_spider -o results.csv
import scrapy
from scrapy.http import Request

class ImdbSpider(scrapy.Spider):
    name = 'tutorial_imdb_spider'
    
    allowed_domains = [
        "imdb.com"
    ]
    
    start_urls = ['https://www.imdb.com/title/tt0098800/']
    
    def parse(self, response):
        title = "The Fresh Prince of Bel-Air"
        useful = response.css('p[data-testid="plot"]')
        plot_html = useful.css('span[data-testid="plot-l"]')
        description = plot_html.css('::text').get()
        yield {
            "My Favorite": title,
            "Plot": description
        }
```

Then you would run it in your python command prompt by typing:\
`scrapy crawl tutorial_imdb_spider -o results.csv`\
It will run and create a csv file called `results.csv` with the information you want.\
\
Now that you have the basics down, lets move on so you can understand how my (simple) imdb scraper works.\
Remember, you can work through most of the code in the scrapy shell!

# Simple IMDB scraper #

This scraper does something pretty simple. First, we start on the imdb page of our favorite show. Then it will navigate to the cast and crew page of the show on IMDB. From there it will create a list of the IMDB pages of every actor in the series cast list from the crew page. It will then go to every actor's IMDB page and extract the name of all the shows in their filmography into a csv file with two rows, one row with the actor's name and another row with the show that they worked on's name.\
To do this we define three functions in our `ImdbSpider` class.

# Method 1 #


```python
def parse(self,response):
"""
This function, which assumes that we are on the IMDB page of a movie or tv show\
will extract a link to the cast and crew list which is also located on IMDB.\
Once we have that link we will call the parse_full_credits method on the cast and crew page.
"""
    # This will extract the path to the full credits page 
    # on IMDB of our favorite show
    creds = response.css("[href^='fullcredits']").attrib["href"]

    # Append the path to the URL of our favorite show to 
    # access its full credits page
    creds_url = response.url+creds

    # Call parse_full_credits on the URL of the full credits page
    yield Request(creds_url, self.parse_full_credits)
```

Hopefully, you can figure most of this out if you understand the basics section of this tutorial and the scrapy shell.\
\
Notice our first css query\
`response.css("[href^='fullcredits']").attrib["href"]`\
\
If you didn't play the game then the `[href^='fullcredits']` is probably unfamiliar to you. What this query to doing is looking for any tag on the page that has the attribute `href` and whose `href` attribute begins will the string `"fullcredits"`.\
If you run this in the scrapy shell, you will note that it will extract a single object.\
\
The `.attrib["href"]` part of the command is going to extract the string that is actually in the `href` attribute. In this instance it happens to be the path of the cast and crew page of our favorite show. For me it was `fullcredits/?ref_=tt_ql_cl`.
If we append this to the url of response, then we will have the full url of the IMDB cast and crew page of our favorite show.\
\
Note: if you type `response.css("[href^='fullcredits']").attrib` in the scrapy shell and it'll output a dictionary that'll give you all the atrribute names as keys and the info they hold as values.\

\
Now we can pass this url to the next method using the `Request` method of the Request package in scrapy.http. Note that this was imported above in our first bit of code on the blog.

# Method 2 #


```python
def parse_full_credits(self,response):
"""
This function, which assumes we are on a cast and crew page of a show on IMDB\
will create a list of URLs to each cast member's IMDB page (only the actors)\
For each actor, we call the parse_actor_page method on their IMDB page
"""
    # Here we extract the path to each of the actor's IMDB page
    actors_list = response.css("table.cast_list td.primary_photo")
    actors_page = [actor.css("a").attrib["href"] for actor in actors_list]

    # Append the path of the actor's IMDB page to the IMDB domain
    actors_urls = ["https://www.imdb.com"+end for end in actors_page]

    # for each actor, we call parse_actor_page for their page.
    for url in actors_urls:
        yield Request(url, self.parse_actor_page)
```

This method will do the work of finding the IMDB page of every actor of our favorite show. As we saw from method 1, we are passing the url of the IMDB cast and crew page from of our first page.\
\
Looking at the cast and crew page, we can see that only the Series Cast table has the images of the actors displayed so our first line\
`actors_list = response.css("table.cast_list td.primary_photo")`\
will effectively go to the cast and crew table on the page then extract every element with the `td` tag with `class = "primary_photo"`\
Then we go on to make a list of each actor's IMDB page path. This is found under the child with tag `a` within the `actors_list` element. The path is saved to the `href` attribute so we'll call the `.attrib` function again.\
\
We can now create a list of the URLs for the IMDB page of the actors and finally call `parse_actor_page`, our final method of our spider, for each page

# Method 3 #


```python
def parse_actor_page(self,response):
"""
This function assumes we are on an actor's IMDB page.
It will extract the name of the actor from the page and the name of every\
show in their filmography.\
Then it will save this to a csv file with two columns:\
    1. The name of the actor
    2. The name of the show that the actor worked on
"""
    # We extract the name of the actor	
    human = response.css("h1.header span.itemprop::text").get()

    # Extract the name of every show in the actor's filmography
    finder = response.css("div.filmo-row")
    work_list = [film.css("a::text").get() for film in finder]

    # Output to a csv as described
    for pixels in work_list:
        yield {
            "Actor": human,
            "Media": pixels
        }
```

This method assumes that we are on an actor's IMDB page as we saw previously.\
Here is where we write our csv file!\
\
Our first line\
`human = response.css("h1.header span.itemprop::text").get()`
will extract the actor's name from the page which is fortunately right at the top of the page. One small change from how we extracted text in the basics function, instead of calling `.css(::text)` we just append the `::text` query to our original query.\
\
Next we will work on compiling the actor's full filmography. Luckily IMDB has it all listed in a table under a `div` tag. So, we can easily extract this data as follows\
`finder = response.css("div.filmo-row")`\
`work_list = [film.css("a::text").get() for film in finder]`\
It was done in two lines for clarity but you can easily combine them into one line.\
\
We now have everything we need so we will yield a dictionary for each show title we extracted.

# Results #

You now have all you need to recreate that same spider that you saw at the start.\ Hopefully you understood the whole process.\
\
Let's run our completed spider. Again, I chose The Fresh Prince of Bel-Air so lets see what we get.\


```python
import pandas as pd
result = pd.read_csv("results.csv")
result.head()
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Actor</th>
      <th>Media</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Richard Roundtree</td>
      <td>Moving On</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Richard Roundtree</td>
      <td>Cherish the Day</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Richard Roundtree</td>
      <td>Family Reunion</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Richard Roundtree</td>
      <td>Haunting of the Mary Celeste</td>
    </tr>
    <tr>
      <th>4</th>
      <td>Richard Roundtree</td>
      <td>Game On! A Comedy Crossover Event</td>
    </tr>
  </tbody>
</table>
</div>



Thats a lot of data.\
\
Let's see if we can't come up with a recommendation for something to watch based on if you like The Fresh Prince of Bel-Air.\
\
Surely, if a show shares many of the same actors then you'll also like that. Right? Hard to say, but let's see what we can get.


```python
import numpy as np

ez_rec = result["Media"].value_counts().reset_index()
ez_rec = ez_rec.rename(columns={"index":"Media","Media": "Number of Actors From FP"})
ez_rec.style.set_properties(**{'text-align':'center'})
recs = ez_rec.head(11)
recs
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Media</th>
      <th>Number of Actors From FP</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>The Fresh Prince of Bel-Air</td>
      <td>742</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Entertainment Tonight</td>
      <td>133</td>
    </tr>
    <tr>
      <th>2</th>
      <td>ER</td>
      <td>114</td>
    </tr>
    <tr>
      <th>3</th>
      <td>L.A. Law</td>
      <td>84</td>
    </tr>
    <tr>
      <th>4</th>
      <td>Living Single</td>
      <td>80</td>
    </tr>
    <tr>
      <th>5</th>
      <td>The Tonight Show with Jay Leno</td>
      <td>77</td>
    </tr>
    <tr>
      <th>6</th>
      <td>Martin</td>
      <td>74</td>
    </tr>
    <tr>
      <th>7</th>
      <td>NYPD Blue</td>
      <td>74</td>
    </tr>
    <tr>
      <th>8</th>
      <td>Days of Our Lives</td>
      <td>74</td>
    </tr>
    <tr>
      <th>9</th>
      <td>E! True Hollywood Story</td>
      <td>71</td>
    </tr>
    <tr>
      <th>10</th>
      <td>Murder, She Wrote</td>
      <td>71</td>
    </tr>
  </tbody>
</table>
</div>



Well, it looks like Entertainment Tonight is the show with the most actors who are also in The Fresh Prince of Bel-Air, besides the Fresh Prince of Bel-Air. Then, there's ER and L.A. Law. So maybe give those a try.\
\
Alternative, in memorial to James Avery, let's make sure that our recommendations above also include him. We'll take the top 30 shows that include James Avery and the most actors from The Fresh Prince of Bel-Air (excluding the Fresh Prince of Bel-Air since this list actually matters).


```python
Uncle_Phil_mask = result["Actor"]=="James Avery"
Uncle_Phil_media = list(result[Uncle_Phil_mask]["Media"])
mask = ez_rec["Media"].isin(Uncle_Phil_media)
Uncle_Phil_rec = ez_rec[mask].iloc[1:30].reset_index()[["Media","Number of Actors From FP"]]
```


```python
Uncle_Phil_rec.style.set_properties(**{'text-align': 'left'})
```




<style type="text/css">
#T_611ad_row0_col0, #T_611ad_row0_col1, #T_611ad_row1_col0, #T_611ad_row1_col1, #T_611ad_row2_col0, #T_611ad_row2_col1, #T_611ad_row3_col0, #T_611ad_row3_col1, #T_611ad_row4_col0, #T_611ad_row4_col1, #T_611ad_row5_col0, #T_611ad_row5_col1, #T_611ad_row6_col0, #T_611ad_row6_col1, #T_611ad_row7_col0, #T_611ad_row7_col1, #T_611ad_row8_col0, #T_611ad_row8_col1, #T_611ad_row9_col0, #T_611ad_row9_col1, #T_611ad_row10_col0, #T_611ad_row10_col1, #T_611ad_row11_col0, #T_611ad_row11_col1, #T_611ad_row12_col0, #T_611ad_row12_col1, #T_611ad_row13_col0, #T_611ad_row13_col1, #T_611ad_row14_col0, #T_611ad_row14_col1, #T_611ad_row15_col0, #T_611ad_row15_col1, #T_611ad_row16_col0, #T_611ad_row16_col1, #T_611ad_row17_col0, #T_611ad_row17_col1, #T_611ad_row18_col0, #T_611ad_row18_col1, #T_611ad_row19_col0, #T_611ad_row19_col1, #T_611ad_row20_col0, #T_611ad_row20_col1, #T_611ad_row21_col0, #T_611ad_row21_col1, #T_611ad_row22_col0, #T_611ad_row22_col1, #T_611ad_row23_col0, #T_611ad_row23_col1, #T_611ad_row24_col0, #T_611ad_row24_col1, #T_611ad_row25_col0, #T_611ad_row25_col1, #T_611ad_row26_col0, #T_611ad_row26_col1, #T_611ad_row27_col0, #T_611ad_row27_col1, #T_611ad_row28_col0, #T_611ad_row28_col1 {
  text-align: left;
}
</style>
<table id="T_611ad_">
  <thead>
    <tr>
      <th class="blank level0" >&nbsp;</th>
      <th class="col_heading level0 col0" >Media</th>
      <th class="col_heading level0 col1" >Number of Actors From FP</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th id="T_611ad_level0_row0" class="row_heading level0 row0" >0</th>
      <td id="T_611ad_row0_col0" class="data row0 col0" >Entertainment Tonight</td>
      <td id="T_611ad_row0_col1" class="data row0 col1" >133</td>
    </tr>
    <tr>
      <th id="T_611ad_level0_row1" class="row_heading level0 row1" >1</th>
      <td id="T_611ad_row1_col0" class="data row1 col0" >L.A. Law</td>
      <td id="T_611ad_row1_col1" class="data row1 col1" >84</td>
    </tr>
    <tr>
      <th id="T_611ad_level0_row2" class="row_heading level0 row2" >2</th>
      <td id="T_611ad_row2_col0" class="data row2 col0" >NYPD Blue</td>
      <td id="T_611ad_row2_col1" class="data row2 col1" >74</td>
    </tr>
    <tr>
      <th id="T_611ad_level0_row3" class="row_heading level0 row3" >3</th>
      <td id="T_611ad_row3_col0" class="data row3 col0" >E! True Hollywood Story</td>
      <td id="T_611ad_row3_col1" class="data row3 col1" >71</td>
    </tr>
    <tr>
      <th id="T_611ad_level0_row4" class="row_heading level0 row4" >4</th>
      <td id="T_611ad_row4_col0" class="data row4 col0" >Hill Street Blues</td>
      <td id="T_611ad_row4_col1" class="data row4 col1" >66</td>
    </tr>
    <tr>
      <th id="T_611ad_level0_row5" class="row_heading level0 row5" >5</th>
      <td id="T_611ad_row5_col0" class="data row5 col0" >Family Matters</td>
      <td id="T_611ad_row5_col1" class="data row5 col1" >60</td>
    </tr>
    <tr>
      <th id="T_611ad_level0_row6" class="row_heading level0 row6" >6</th>
      <td id="T_611ad_row6_col0" class="data row6 col0" >A Different World</td>
      <td id="T_611ad_row6_col1" class="data row6 col1" >57</td>
    </tr>
    <tr>
      <th id="T_611ad_level0_row7" class="row_heading level0 row7" >7</th>
      <td id="T_611ad_row7_col0" class="data row7 col0" >The Jamie Foxx Show</td>
      <td id="T_611ad_row7_col1" class="data row7 col1" >54</td>
    </tr>
    <tr>
      <th id="T_611ad_level0_row8" class="row_heading level0 row8" >8</th>
      <td id="T_611ad_row8_col0" class="data row8 col0" >The Young and the Restless</td>
      <td id="T_611ad_row8_col1" class="data row8 col1" >52</td>
    </tr>
    <tr>
      <th id="T_611ad_level0_row9" class="row_heading level0 row9" >9</th>
      <td id="T_611ad_row9_col0" class="data row9 col0" >The Tonight Show Starring Johnny Carson</td>
      <td id="T_611ad_row9_col1" class="data row9 col1" >51</td>
    </tr>
    <tr>
      <th id="T_611ad_level0_row10" class="row_heading level0 row10" >10</th>
      <td id="T_611ad_row10_col0" class="data row10 col0" >Biography</td>
      <td id="T_611ad_row10_col1" class="data row10 col1" >50</td>
    </tr>
    <tr>
      <th id="T_611ad_level0_row11" class="row_heading level0 row11" >11</th>
      <td id="T_611ad_row11_col0" class="data row11 col0" >The Magical World of Disney</td>
      <td id="T_611ad_row11_col1" class="data row11 col1" >48</td>
    </tr>
    <tr>
      <th id="T_611ad_level0_row12" class="row_heading level0 row12" >12</th>
      <td id="T_611ad_row12_col0" class="data row12 col0" >Ebony/Jet Showcase</td>
      <td id="T_611ad_row12_col1" class="data row12 col1" >47</td>
    </tr>
    <tr>
      <th id="T_611ad_level0_row13" class="row_heading level0 row13" >13</th>
      <td id="T_611ad_row13_col0" class="data row13 col0" >Live with Kelly and Ryan</td>
      <td id="T_611ad_row13_col1" class="data row13 col1" >46</td>
    </tr>
    <tr>
      <th id="T_611ad_level0_row14" class="row_heading level0 row14" >14</th>
      <td id="T_611ad_row14_col0" class="data row14 col0" >227</td>
      <td id="T_611ad_row14_col1" class="data row14 col1" >46</td>
    </tr>
    <tr>
      <th id="T_611ad_level0_row15" class="row_heading level0 row15" >15</th>
      <td id="T_611ad_row15_col0" class="data row15 col0" >Roc</td>
      <td id="T_611ad_row15_col1" class="data row15 col1" >44</td>
    </tr>
    <tr>
      <th id="T_611ad_level0_row16" class="row_heading level0 row16" >16</th>
      <td id="T_611ad_row16_col0" class="data row16 col0" >An Evening at the Improv</td>
      <td id="T_611ad_row16_col1" class="data row16 col1" >44</td>
    </tr>
    <tr>
      <th id="T_611ad_level0_row17" class="row_heading level0 row17" >17</th>
      <td id="T_611ad_row17_col0" class="data row17 col0" >Grey's Anatomy</td>
      <td id="T_611ad_row17_col1" class="data row17 col1" >44</td>
    </tr>
    <tr>
      <th id="T_611ad_level0_row18" class="row_heading level0 row18" >18</th>
      <td id="T_611ad_row18_col0" class="data row18 col0" >Night Court</td>
      <td id="T_611ad_row18_col1" class="data row18 col1" >42</td>
    </tr>
    <tr>
      <th id="T_611ad_level0_row19" class="row_heading level0 row19" >19</th>
      <td id="T_611ad_row19_col0" class="data row19 col0" >Amen</td>
      <td id="T_611ad_row19_col1" class="data row19 col1" >42</td>
    </tr>
    <tr>
      <th id="T_611ad_level0_row20" class="row_heading level0 row20" >20</th>
      <td id="T_611ad_row20_col0" class="data row20 col0" >CSI: Crime Scene Investigation</td>
      <td id="T_611ad_row20_col1" class="data row20 col1" >42</td>
    </tr>
    <tr>
      <th id="T_611ad_level0_row21" class="row_heading level0 row21" >21</th>
      <td id="T_611ad_row21_col0" class="data row21 col0" >Happily Ever After: Fairy Tales for Every Child</td>
      <td id="T_611ad_row21_col1" class="data row21 col1" >40</td>
    </tr>
    <tr>
      <th id="T_611ad_level0_row22" class="row_heading level0 row22" >22</th>
      <td id="T_611ad_row22_col0" class="data row22 col0" >In the House</td>
      <td id="T_611ad_row22_col1" class="data row22 col1" >39</td>
    </tr>
    <tr>
      <th id="T_611ad_level0_row23" class="row_heading level0 row23" >23</th>
      <td id="T_611ad_row23_col0" class="data row23 col0" >Simon & Simon</td>
      <td id="T_611ad_row23_col1" class="data row23 col1" >38</td>
    </tr>
    <tr>
      <th id="T_611ad_level0_row24" class="row_heading level0 row24" >24</th>
      <td id="T_611ad_row24_col0" class="data row24 col0" >Judging Amy</td>
      <td id="T_611ad_row24_col1" class="data row24 col1" >35</td>
    </tr>
    <tr>
      <th id="T_611ad_level0_row25" class="row_heading level0 row25" >25</th>
      <td id="T_611ad_row25_col0" class="data row25 col0" >The Jeffersons</td>
      <td id="T_611ad_row25_col1" class="data row25 col1" >32</td>
    </tr>
    <tr>
      <th id="T_611ad_level0_row26" class="row_heading level0 row26" >26</th>
      <td id="T_611ad_row26_col0" class="data row26 col0" >Dallas</td>
      <td id="T_611ad_row26_col1" class="data row26 col1" >31</td>
    </tr>
    <tr>
      <th id="T_611ad_level0_row27" class="row_heading level0 row27" >27</th>
      <td id="T_611ad_row27_col0" class="data row27 col0" >St. Elsewhere</td>
      <td id="T_611ad_row27_col1" class="data row27 col1" >29</td>
    </tr>
    <tr>
      <th id="T_611ad_level0_row28" class="row_heading level0 row28" >28</th>
      <td id="T_611ad_row28_col0" class="data row28 col0" >Strong Medicine</td>
      <td id="T_611ad_row28_col1" class="data row28 col1" >29</td>
    </tr>
  </tbody>
</table>




# Arrival #
I hope you learned something or are about to watch some shows that include James Avery.\
\
Thank you for choosing scraping_airlines, we at scraping_airlines know you had many choices and unfortunately you chose us.
