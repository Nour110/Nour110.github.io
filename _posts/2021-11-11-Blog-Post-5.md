---
layout: post
title: Blog Post 5
---

Hi and welcome to another blog post. In this post, we'll be going over image classification and using tensorflow. We'll begin by importing some packages. Note that this post was written using Google Colab as getting tensorflow to work and function properly using anaconda can cause a lot of headaches.


```python
import os
import numpy as np
import tensorflow as tf
from tensorflow.keras import utils,layers
from matplotlib import pyplot as plt
```

The code block below will create TensorFlow Datasets for training, validation, and testing. These data sets will be used to feed data to our models as loading all the data at once would be inpractical.

We're going to use a keras utility called `image_dataset_from_directory` to construct our Dataset. The first argument will specify where the images are located. The shuffle argument will randomize the order in which the data is retrieved. The batch_size determines how many data points are gathered from the directory at once. So, each time we request data we will get 32 images from each of the data sets. Finally, the image_size specifies the size of the input images.


```python
# location of data
_URL = 'https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip'

# download the data and extract it
path_to_zip = utils.get_file('cats_and_dogs.zip', origin=_URL, extract=True)

# construct paths
PATH = os.path.join(os.path.dirname(path_to_zip), 'cats_and_dogs_filtered')

train_dir = os.path.join(PATH, 'train')
validation_dir = os.path.join(PATH, 'validation')

# parameters for datasets
BATCH_SIZE = 32
IMG_SIZE = (160, 160)

# construct train and validation datasets 
train_dataset = utils.image_dataset_from_directory(train_dir,
                                                   shuffle=True,
                                                   batch_size=BATCH_SIZE,
                                                   image_size=IMG_SIZE)

validation_dataset = utils.image_dataset_from_directory(validation_dir,
                                                        shuffle=True,
                                                        batch_size=BATCH_SIZE,
                                                        image_size=IMG_SIZE)

# construct the test dataset by taking every 5th observation out of the validation dataset
val_batches = tf.data.experimental.cardinality(validation_dataset)
test_dataset = validation_dataset.take(val_batches // 5)
validation_dataset = validation_dataset.skip(val_batches // 5)
```

    Found 2000 files belonging to 2 classes.
    Found 1000 files belonging to 2 classes.
    

The next block is a mystery unless you decide you want to learn more, which you can by following this link:\
https://www.tensorflow.org/guide/data_performance


```python
AUTOTUNE = tf.data.AUTOTUNE

train_dataset = train_dataset.prefetch(buffer_size=AUTOTUNE)
validation_dataset = validation_dataset.prefetch(buffer_size=AUTOTUNE)
test_dataset = test_dataset.prefetch(buffer_size=AUTOTUNE)
```

We're gonna just quickly pull an image out for use latter. Don't mind me.


```python
example = train_dataset.take(1).get_single_element()[0][0]/255.0
```


```python
data = train_dataset.take(1).get_single_element()[:][:]
data[1][3],data[1][0]
type(data[0])
```




    tensorflow.python.framework.ops.EagerTensor



Our data is just a bunch of images with an associated label for every image. Each image is either a picture of a dog or a picture of dog and they are labeled as such. Let's write a function to pull out and show three random images of cats on one row and three random images of dogs on the second row.




```python
def cat_dog():
  # we will pull a batch from our training dataset
  # this be a tuple of tf "arrays"
  # in the first element of the tuple we will have the images
  # in the second element we will have the labels
  # 0 corresponds to cats
  # 1 corresponds to dogs

  data = train_dataset.take(1).get_single_element()[:][:]

  # initialize empty lists
  cats = []
  dogs = []
  # this for loop will populate our lists with the correct images
  for i in range(len(data[0])):
    if data[1][i] == 0:
      cats.append(data[0][i])
    else:
      dogs.append(data[0][i])

  # we now make a plt figure to show the images
  fig,ax = plt.subplots(2,3,figsize = (10,10))
  for j in range(3):
    ax[0][j].imshow(cats[j]/255.0)
    ax[1][j].imshow(dogs[j]/255.0)
    ax[0][j].axis("off")
    ax[1][j].axis("off")
    
```


```python
cat_dog()
```


    
![BP5_0]({{ site.baseurl }}/images/BP5_0.png)
    


For our base case, (our base "model"), we will just guess the most frequent label. Let's count how many images of dogs and cats there are in our whole training data to see how we would expect our base model to perform.




```python
labels_iterator= train_dataset.unbatch().map(lambda image, label: label).as_numpy_iterator()
```


```python
cat_count = 0
dog_count = 0

for i in labels_iterator:
  if i == 0:
    cat_count = cat_count+1
  else:
    dog_count = dog_count+1
```


```python
cat_count,dog_count
```




    (1000, 1000)



So, there are the same number of cat and dog images in our training data. Since we are selecting them randomly for each batch, we would expect that our batch would contain 16 cat images and 16 dog images. So, our base model would have an accuracy of 50%. Not really that great. 

# First Model #
So, let's now build our first model. To do this we are going to use `tf.keras.models.Sequential` and specify a number of layers. What does this mean?\
Well, to put it very simply, layers are a basic building block of a neural network. They will effectively be taking our data and altering them in order to come up with a different representation of the data that will hopefully help the network as a whole classify data.\
`tf.keras.models.Sequential` is just a function that will handle all of these different layers and apply them to our data in a sequence and spit out a prediction.


```python
# this is our first model.

model1 = tf.keras.models.Sequential([
                                     # input layer
                                     layers.Conv2D(32,(4,4),activation = 'relu',input_shape=(160,160,3)),

                                     # hidden layers
                                     layers.MaxPooling2D((2,2)),
                                     layers.Dense(64,activation = 'relu'),
                                     layers.Dropout(0.35),
                                     layers.Conv2D(16,(3,3),activation = 'relu'),
                                     layers.MaxPooling2D((3,3)),
                                     layers.Flatten(),
                                     layers.Dense(32,activation = 'relu'),

                                     # output layer
                                     layers.Dense(2)                                    
])
```

If you would like a detailed explanation of each of the layers, you may refer to \
https://www.tensorflow.org/api_docs/python/tf/keras/layers/AveragePooling2D \
There are some very basic image processing concepts and I'd encourage you to dive even deeper into mathematical imaging but for now I would like for you to note a couple things here: \
1) Notice how in our first layer, the input layer, we specified the shape of the data that we will be inputting. Here, as we saw above, we will be inputting images with the shape (160,160,3).\
2) Our last layer which is our output layer, the parameter that we specified is 2. This is because for our specific image classification task, we have only 2 choices, we either have an image of a dog or a cat.

Now, we will compile our model. This will conveniently be handled by the `tf.keras.models` package again using the `.compile` method.\
We will specificy a few parameters here.\
First we are going to specificy an "optimizer". This will help guide the model in how it will update based on the data it sees and the loss function that we will specify.\
Second we will pick a loss function for the "loss" parameter. This will measure the accuracy of the model during training.\
Finally, we will specify the metrics which is just the parameters that will be displayed while the model is going through and training.



```python
model1.compile(optimizer='adam',
              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
              metrics=['accuracy'])
```

Now, we must actually start training our model on the data. Let's go ahead and do that using the training dataset and the validation dataset. The Validation dataset will not actually be used for training but rather to help guide our model in how it will update in the next epoch.\ 
We are going to be training our model on 20 epochs. Our model is going to essentially update after each epoch and try to adjust based on how well it did in the previous epoch.


```python
history = model1.fit(train_dataset,
                     epochs=20,
                     validation_data=validation_dataset)
```

    Epoch 1/20
    63/63 [==============================] - 6s 77ms/step - loss: 7.6122 - accuracy: 0.5135 - val_loss: 0.6931 - val_accuracy: 0.5037
    Epoch 2/20
    63/63 [==============================] - 5s 69ms/step - loss: 0.6928 - accuracy: 0.5265 - val_loss: 0.6931 - val_accuracy: 0.5037
    Epoch 3/20
    63/63 [==============================] - 5s 71ms/step - loss: 0.6901 - accuracy: 0.5420 - val_loss: 0.6935 - val_accuracy: 0.4926
    Epoch 4/20
    63/63 [==============================] - 5s 70ms/step - loss: 0.6700 - accuracy: 0.5935 - val_loss: 0.6845 - val_accuracy: 0.5532
    Epoch 5/20
    63/63 [==============================] - 5s 72ms/step - loss: 0.6273 - accuracy: 0.6385 - val_loss: 0.6971 - val_accuracy: 0.5483
    Epoch 6/20
    63/63 [==============================] - 5s 73ms/step - loss: 0.5816 - accuracy: 0.6860 - val_loss: 0.7050 - val_accuracy: 0.5582
    Epoch 7/20
    63/63 [==============================] - 5s 73ms/step - loss: 0.5236 - accuracy: 0.7260 - val_loss: 0.7702 - val_accuracy: 0.5656
    Epoch 8/20
    63/63 [==============================] - 5s 73ms/step - loss: 0.4443 - accuracy: 0.7830 - val_loss: 0.8269 - val_accuracy: 0.5730
    Epoch 9/20
    63/63 [==============================] - 5s 70ms/step - loss: 0.3961 - accuracy: 0.8110 - val_loss: 1.1312 - val_accuracy: 0.5718
    Epoch 10/20
    63/63 [==============================] - 5s 74ms/step - loss: 0.2898 - accuracy: 0.8730 - val_loss: 1.1412 - val_accuracy: 0.5804
    Epoch 11/20
    63/63 [==============================] - 5s 73ms/step - loss: 0.2234 - accuracy: 0.9100 - val_loss: 1.3466 - val_accuracy: 0.5792
    Epoch 12/20
    63/63 [==============================] - 5s 75ms/step - loss: 0.2040 - accuracy: 0.9150 - val_loss: 1.4129 - val_accuracy: 0.5928
    Epoch 13/20
    63/63 [==============================] - 5s 72ms/step - loss: 0.1760 - accuracy: 0.9325 - val_loss: 1.8292 - val_accuracy: 0.5780
    Epoch 14/20
    63/63 [==============================] - 5s 74ms/step - loss: 0.1283 - accuracy: 0.9510 - val_loss: 1.9261 - val_accuracy: 0.5879
    Epoch 15/20
    63/63 [==============================] - 5s 73ms/step - loss: 0.1118 - accuracy: 0.9600 - val_loss: 1.9805 - val_accuracy: 0.5743
    Epoch 16/20
    63/63 [==============================] - 5s 72ms/step - loss: 0.0831 - accuracy: 0.9705 - val_loss: 2.3174 - val_accuracy: 0.5891
    Epoch 17/20
    63/63 [==============================] - 5s 74ms/step - loss: 0.0593 - accuracy: 0.9820 - val_loss: 2.3843 - val_accuracy: 0.5817
    Epoch 18/20
    63/63 [==============================] - 5s 75ms/step - loss: 0.0598 - accuracy: 0.9800 - val_loss: 2.4426 - val_accuracy: 0.5705
    Epoch 19/20
    63/63 [==============================] - 5s 77ms/step - loss: 0.0782 - accuracy: 0.9725 - val_loss: 2.4226 - val_accuracy: 0.5681
    Epoch 20/20
    63/63 [==============================] - 5s 73ms/step - loss: 0.0732 - accuracy: 0.9850 - val_loss: 2.2781 - val_accuracy: 0.5941
    


```python
plt.plot(history.history["accuracy"], label = "training")
plt.plot(history.history["val_accuracy"], label = "validation")
plt.gca().set(xlabel = "epoch", ylabel = "accuracy")
plt.legend()
```




    <matplotlib.legend.Legend at 0x7f30c65ebbd0>




    
![BP5_1]({{ site.baseurl }}/images/BP5_1.png)
    


So, as you can see our model has done better than a random guess (allegedly).\
This model seems to be stable **between 57% to 59%%**. Unfortunately, as you can see the accuracy on the training data is substantially higher than that of the validation data. So, we are definitely overfitting here.\
I've tried to ammend this problem using different layers and parameters for those layers but this model seemed to have had the best performance on the validation set.\
I tried to move the dropout layer further up which did fix the overfitting but the model was stagnated at or below 50% for both the training data and the validation data. Increasing the first parameter in the Dense layers, resulted in even more overfitting of the training data and surprisingly lower validation scores. I tried several other things but I won't go into too much detail. Instead, try running this yourself and mess around with the layers and see what kind of results you get and try to understand how the model may be changing.\ 
Comparing to the baseline, we did about 10% better which isn't so bad!  

# Model with Data Augmentation #

So, we're going to use some data augmentation layers in our model. This is just a fancy way if saying that we're going to include modified copies of our input images to help train our model.


```python
# Let's start with just randomly flipping the images
flip = tf.keras.layers.RandomFlip(input_shape = (160,160,3))
fig,ax = plt.subplots(2,2)
ax[0][0].imshow(example)
ax[0][1].imshow(flip(example))
ax[1][0].imshow(flip(example))
ax[1][1].imshow(flip(example))

```




    <matplotlib.image.AxesImage at 0x7f5ed76cd690>




    
![BP5_2]({{ site.baseurl }}/images/BP5_2.png)
    


As you can see above, this layer will just flip the image horizontally or vertically. Nothing really complicated about that. Adding this layer will help our model learn *invariant* features of the input image.\
\
The next layer is going to have much the same purpose.


```python
rotator = tf.keras.layers.RandomRotation(factor = ((-2*np.pi,2*np.pi)),
                                         fill_mode = "reflect",
                                         interpolation = "bilinear")
fig,ax = plt.subplots(2,2)
ax[0][0].imshow(example)
ax[0][1].imshow(rotator(example))
ax[1][0].imshow(rotator(example))
ax[1][1].imshow(rotator(example))
```




    <matplotlib.image.AxesImage at 0x7f5ed7400690>




    
![BP5_3]({{ site.baseurl }}/images/BP5_3.png)
    


That's right, we're rotating the image around!\
Now lets create our model just as we did before but now we'll add these layers!


```python
model2 = tf.keras.models.Sequential([
                                     # input layer
                                     tf.keras.layers.RandomFlip(input_shape = (160,160,3)),
                                     tf.keras.layers.RandomRotation(factor = ((-2*np.pi,2*np.pi)),
                                         fill_mode = "reflect",
                                         interpolation = "bilinear"),
                                     
                                      # hidden layers
                                     layers.Conv2D(32,(4,4),activation = 'relu',input_shape=(160,160,3)),
                                     layers.MaxPooling2D((2,2)),
                                     layers.Dense(64,activation = 'relu'),
                                     
                                     layers.Conv2D(16,(3,3),activation = 'relu'),
                                     layers.MaxPooling2D((3,3)),
                                     layers.Flatten(),
                                     layers.Dense(32,activation = 'relu'),

                                     # output layer
                                     layers.Dense(2)                                    
])

model2.compile(optimizer='adam',
              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
              metrics=['accuracy'])
```


```python
history = model2.fit(train_dataset, 
                     epochs=20,
                     validation_data=validation_dataset)
```

    Epoch 1/20
    63/63 [==============================] - 6s 75ms/step - loss: 11.4799 - accuracy: 0.5185 - val_loss: 0.6930 - val_accuracy: 0.5087
    Epoch 2/20
    63/63 [==============================] - 5s 72ms/step - loss: 0.6924 - accuracy: 0.5160 - val_loss: 0.6851 - val_accuracy: 0.5594
    Epoch 3/20
    63/63 [==============================] - 5s 73ms/step - loss: 0.6892 - accuracy: 0.5515 - val_loss: 0.6787 - val_accuracy: 0.5705
    Epoch 4/20
    63/63 [==============================] - 5s 73ms/step - loss: 0.6847 - accuracy: 0.5645 - val_loss: 0.6703 - val_accuracy: 0.5916
    Epoch 5/20
    63/63 [==============================] - 5s 68ms/step - loss: 0.6804 - accuracy: 0.5820 - val_loss: 0.6682 - val_accuracy: 0.5928
    Epoch 6/20
    63/63 [==============================] - 5s 71ms/step - loss: 0.6803 - accuracy: 0.5865 - val_loss: 0.6639 - val_accuracy: 0.5965
    Epoch 7/20
    63/63 [==============================] - 5s 69ms/step - loss: 0.6741 - accuracy: 0.5970 - val_loss: 0.6609 - val_accuracy: 0.6052
    Epoch 8/20
    63/63 [==============================] - 5s 72ms/step - loss: 0.6795 - accuracy: 0.5740 - val_loss: 0.6854 - val_accuracy: 0.5903
    Epoch 9/20
    63/63 [==============================] - 5s 69ms/step - loss: 0.6765 - accuracy: 0.5875 - val_loss: 0.6796 - val_accuracy: 0.5792
    Epoch 10/20
    63/63 [==============================] - 5s 73ms/step - loss: 0.6755 - accuracy: 0.5885 - val_loss: 0.6872 - val_accuracy: 0.5359
    Epoch 11/20
    63/63 [==============================] - 5s 74ms/step - loss: 0.6706 - accuracy: 0.5920 - val_loss: 0.6738 - val_accuracy: 0.6126
    Epoch 12/20
    63/63 [==============================] - 5s 70ms/step - loss: 0.6625 - accuracy: 0.6100 - val_loss: 0.6718 - val_accuracy: 0.5903
    Epoch 13/20
    63/63 [==============================] - 5s 71ms/step - loss: 0.6608 - accuracy: 0.6280 - val_loss: 0.6663 - val_accuracy: 0.6077
    Epoch 14/20
    63/63 [==============================] - 5s 70ms/step - loss: 0.6665 - accuracy: 0.6210 - val_loss: 0.6662 - val_accuracy: 0.6238
    Epoch 15/20
    63/63 [==============================] - 5s 73ms/step - loss: 0.6539 - accuracy: 0.6200 - val_loss: 0.6741 - val_accuracy: 0.6114
    Epoch 16/20
    63/63 [==============================] - 5s 73ms/step - loss: 0.6601 - accuracy: 0.6320 - val_loss: 0.6700 - val_accuracy: 0.5916
    Epoch 17/20
    63/63 [==============================] - 5s 74ms/step - loss: 0.6597 - accuracy: 0.6065 - val_loss: 0.6800 - val_accuracy: 0.6151
    Epoch 18/20
    63/63 [==============================] - 5s 72ms/step - loss: 0.6471 - accuracy: 0.6360 - val_loss: 0.6721 - val_accuracy: 0.6275
    Epoch 19/20
    63/63 [==============================] - 5s 70ms/step - loss: 0.6476 - accuracy: 0.6310 - val_loss: 0.6718 - val_accuracy: 0.6064
    Epoch 20/20
    63/63 [==============================] - 5s 71ms/step - loss: 0.6543 - accuracy: 0.6125 - val_loss: 0.6890 - val_accuracy: 0.6040
    


```python
plt.plot(history.history["accuracy"], label = "training")
plt.plot(history.history["val_accuracy"], label = "validation")
plt.gca().set(xlabel = "epoch", ylabel = "accuracy")
plt.legend()
```




    <matplotlib.legend.Legend at 0x7f30de039710>




    
![BP5_4]({{ site.baseurl }}/images/BP5_4.png)
    


Hey look at that! We did a bit better than our first model.\
This time our model is hovering around **59% to 61%**. The problem of overfitting seems to be gone as our accuracy on the training data is around the same as the validation data score! That's great and our loss function is much lower on our validation data as well. I'd say that this is a better model than our first model even though validation scores are about the same.\
Still this model only performed a bit better than the first one and our scores weren't anything spectacular. Let's see what else we can do to improve.\
Onwards to our next model!

#Data Preprocessing#
As we are dealing with machine learning, it can be useful or necessary to preprocess the data in order to free up our model to handle signals in the data rather than processing the data itself.\ 
We're going to create a layer which we will call `preprocessor`. We can pass this as one of the arguments for `tf.keras.models.Sequential` and it will then preprocess the data before it begins training.


```python
# these lines will create our preprocessing layer
i = tf.keras.Input(shape=(160, 160, 3))
x = tf.keras.applications.mobilenet_v2.preprocess_input(i)
preprocessor = tf.keras.Model(inputs = [i], outputs = [x])
```


```python
model3 = tf.keras.models.Sequential([
                                     preprocessor,
                                     # input layer
                                     tf.keras.layers.RandomFlip(input_shape = (160,160,3)),
                                     tf.keras.layers.RandomRotation(factor = ((-2*np.pi,2*np.pi)),
                                         fill_mode = "reflect",
                                         interpolation = "bilinear"),
                                     
                                      # hidden layers
                                     layers.Conv2D(32,(4,4),activation = 'relu',input_shape=(160,160,3)),
                                     layers.MaxPooling2D((2,2)),
                                     layers.Dense(64,activation = 'relu'),
                                     
                                     layers.Conv2D(32,(3,3),activation = 'relu'),
                                     layers.MaxPooling2D((3,3)),
                                     layers.Flatten(),
                                     layers.Dense(32,activation = 'relu'),

                                     # output layer
                                     layers.Dense(2)                                    
])

model3.compile(optimizer='adam',
              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
              metrics=['accuracy'])
```


```python
history = model3.fit(train_dataset, 
                     epochs=20,
                     validation_data=validation_dataset)
```

    Epoch 1/20
    63/63 [==============================] - 6s 73ms/step - loss: 0.6981 - accuracy: 0.4905 - val_loss: 0.6866 - val_accuracy: 0.5483
    Epoch 2/20
    63/63 [==============================] - 5s 73ms/step - loss: 0.6678 - accuracy: 0.5685 - val_loss: 0.6907 - val_accuracy: 0.5297
    Epoch 3/20
    63/63 [==============================] - 5s 74ms/step - loss: 0.6568 - accuracy: 0.5960 - val_loss: 0.6487 - val_accuracy: 0.6151
    Epoch 4/20
    63/63 [==============================] - 5s 68ms/step - loss: 0.6414 - accuracy: 0.6325 - val_loss: 0.6370 - val_accuracy: 0.6324
    Epoch 5/20
    63/63 [==============================] - 5s 71ms/step - loss: 0.6229 - accuracy: 0.6505 - val_loss: 0.6263 - val_accuracy: 0.6535
    Epoch 6/20
    63/63 [==============================] - 5s 72ms/step - loss: 0.6228 - accuracy: 0.6420 - val_loss: 0.6350 - val_accuracy: 0.6300
    Epoch 7/20
    63/63 [==============================] - 5s 73ms/step - loss: 0.6097 - accuracy: 0.6605 - val_loss: 0.6278 - val_accuracy: 0.6374
    Epoch 8/20
    63/63 [==============================] - 5s 70ms/step - loss: 0.6209 - accuracy: 0.6540 - val_loss: 0.6160 - val_accuracy: 0.6572
    Epoch 9/20
    63/63 [==============================] - 5s 74ms/step - loss: 0.5956 - accuracy: 0.6695 - val_loss: 0.6029 - val_accuracy: 0.6708
    Epoch 10/20
    63/63 [==============================] - 5s 75ms/step - loss: 0.5835 - accuracy: 0.6885 - val_loss: 0.5931 - val_accuracy: 0.6733
    Epoch 11/20
    63/63 [==============================] - 5s 71ms/step - loss: 0.5890 - accuracy: 0.6805 - val_loss: 0.6034 - val_accuracy: 0.6844
    Epoch 12/20
    63/63 [==============================] - 5s 75ms/step - loss: 0.5775 - accuracy: 0.6910 - val_loss: 0.5986 - val_accuracy: 0.6559
    Epoch 13/20
    63/63 [==============================] - 5s 73ms/step - loss: 0.5802 - accuracy: 0.6825 - val_loss: 0.5864 - val_accuracy: 0.6696
    Epoch 14/20
    63/63 [==============================] - 5s 73ms/step - loss: 0.5722 - accuracy: 0.7025 - val_loss: 0.6108 - val_accuracy: 0.6782
    Epoch 15/20
    63/63 [==============================] - 5s 69ms/step - loss: 0.5573 - accuracy: 0.7060 - val_loss: 0.6166 - val_accuracy: 0.6696
    Epoch 16/20
    63/63 [==============================] - 5s 71ms/step - loss: 0.5552 - accuracy: 0.7025 - val_loss: 0.5875 - val_accuracy: 0.6955
    Epoch 17/20
    63/63 [==============================] - 5s 72ms/step - loss: 0.5628 - accuracy: 0.7020 - val_loss: 0.5965 - val_accuracy: 0.6844
    Epoch 18/20
    63/63 [==============================] - 5s 74ms/step - loss: 0.5603 - accuracy: 0.7035 - val_loss: 0.5765 - val_accuracy: 0.6993
    Epoch 19/20
    63/63 [==============================] - 5s 74ms/step - loss: 0.5409 - accuracy: 0.7230 - val_loss: 0.5906 - val_accuracy: 0.6943
    Epoch 20/20
    63/63 [==============================] - 5s 72ms/step - loss: 0.5451 - accuracy: 0.7175 - val_loss: 0.5851 - val_accuracy: 0.7141
    


```python
plt.plot(history.history["accuracy"], label = "training")
plt.plot(history.history["val_accuracy"], label = "validation")
plt.gca().set(xlabel = "epoch", ylabel = "accuracy")
plt.legend()
```




    <matplotlib.legend.Legend at 0x7f30c500a8d0>




    
![BP5_5]({{ site.baseurl }}/images/BP5_5.png)
    


As you can see, we have increased our performance by a good amount this time.\ 
Our model was able to achieve an accuracy of **over 70%** after 20 epochs and seems to have stabilised around 70% this time. Again, we did not run into the problem of overfitting as our validation scores and training scores were within 1% of each other.\
We've improved a good deal from our first model. 70% accuracy isn't so bad but we can probably do better.\

# Transfer Learning #
So, we've gotten 70% accuracy. Surely though, there must be an image recognition model that already exists. Maybe our model can take some notes from that. Indeed, doing so is quite simple. And luckily, image recognition is pretty popular subject. Let's borrow one such model and configure it as a layer that our model can borrow notes from.


```python
IMG_SHAPE = IMG_SIZE + (3,)
base_model = tf.keras.applications.MobileNetV2(input_shape=IMG_SHAPE,
                                               include_top=False,
                                               weights='imagenet')
base_model.trainable = False

i = tf.keras.Input(shape=IMG_SHAPE)
x = base_model(i, training = False)
base_model_layer = tf.keras.Model(inputs = [i], outputs = [x])
```

Neat! The above code block created our new layer so let's add it to our model and see how it performs!


```python
model4 = tf.keras.models.Sequential([
                                     #preprocessing layer
                                     preprocessor,
                                     # input layers
                                     layers.RandomRotation(factor = ((-2*np.pi,2*np.pi))),
                                     layers.RandomFlip(),
                                     # hidden layer
                                     base_model_layer,
                                     layers.GlobalMaxPool2D(),
                                     # output layer
                                     layers.Dense(2)
                                     ])

model4.compile(optimizer='adam',
              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
              metrics=['accuracy'])
```


```python
history = model4.fit(train_dataset, 
                     epochs=20,
                     validation_data=validation_dataset)
```

    Epoch 1/20
    63/63 [==============================] - 13s 117ms/step - loss: 0.9189 - accuracy: 0.7600 - val_loss: 0.1490 - val_accuracy: 0.9480
    Epoch 2/20
    63/63 [==============================] - 6s 91ms/step - loss: 0.4154 - accuracy: 0.8695 - val_loss: 0.1235 - val_accuracy: 0.9641
    Epoch 3/20
    63/63 [==============================] - 6s 93ms/step - loss: 0.3464 - accuracy: 0.8895 - val_loss: 0.1007 - val_accuracy: 0.9629
    Epoch 4/20
    63/63 [==============================] - 6s 96ms/step - loss: 0.3144 - accuracy: 0.8940 - val_loss: 0.0959 - val_accuracy: 0.9691
    Epoch 5/20
    63/63 [==============================] - 6s 94ms/step - loss: 0.3030 - accuracy: 0.8995 - val_loss: 0.1022 - val_accuracy: 0.9616
    Epoch 6/20
    63/63 [==============================] - 6s 93ms/step - loss: 0.2475 - accuracy: 0.9175 - val_loss: 0.1011 - val_accuracy: 0.9678
    Epoch 7/20
    63/63 [==============================] - 6s 95ms/step - loss: 0.2718 - accuracy: 0.9220 - val_loss: 0.1540 - val_accuracy: 0.9530
    Epoch 8/20
    63/63 [==============================] - 6s 94ms/step - loss: 0.2686 - accuracy: 0.9120 - val_loss: 0.1028 - val_accuracy: 0.9715
    Epoch 9/20
    63/63 [==============================] - 6s 91ms/step - loss: 0.3718 - accuracy: 0.8865 - val_loss: 0.1085 - val_accuracy: 0.9703
    Epoch 10/20
    63/63 [==============================] - 6s 95ms/step - loss: 0.2742 - accuracy: 0.9140 - val_loss: 0.0918 - val_accuracy: 0.9691
    Epoch 11/20
    63/63 [==============================] - 6s 94ms/step - loss: 0.2313 - accuracy: 0.9215 - val_loss: 0.1101 - val_accuracy: 0.9691
    Epoch 12/20
    63/63 [==============================] - 6s 95ms/step - loss: 0.2645 - accuracy: 0.9170 - val_loss: 0.1006 - val_accuracy: 0.9666
    Epoch 13/20
    63/63 [==============================] - 6s 96ms/step - loss: 0.2402 - accuracy: 0.9160 - val_loss: 0.0925 - val_accuracy: 0.9728
    Epoch 14/20
    63/63 [==============================] - 6s 94ms/step - loss: 0.2330 - accuracy: 0.9250 - val_loss: 0.0971 - val_accuracy: 0.9703
    Epoch 15/20
    63/63 [==============================] - 6s 95ms/step - loss: 0.2101 - accuracy: 0.9240 - val_loss: 0.0888 - val_accuracy: 0.9752
    Epoch 16/20
    63/63 [==============================] - 6s 97ms/step - loss: 0.2333 - accuracy: 0.9240 - val_loss: 0.1299 - val_accuracy: 0.9567
    Epoch 17/20
    63/63 [==============================] - 6s 94ms/step - loss: 0.1937 - accuracy: 0.9285 - val_loss: 0.1105 - val_accuracy: 0.9678
    Epoch 18/20
    63/63 [==============================] - 6s 96ms/step - loss: 0.2010 - accuracy: 0.9335 - val_loss: 0.1478 - val_accuracy: 0.9505
    Epoch 19/20
    63/63 [==============================] - 6s 94ms/step - loss: 0.1920 - accuracy: 0.9320 - val_loss: 0.0901 - val_accuracy: 0.9653
    Epoch 20/20
    63/63 [==============================] - 6s 92ms/step - loss: 0.2171 - accuracy: 0.9290 - val_loss: 0.1117 - val_accuracy: 0.9629
    

Now to visualize these beautiful results.


```python
plt.plot(history.history["accuracy"], label = "training")
plt.plot(history.history["val_accuracy"], label = "validation")
plt.gca().set(xlabel = "epoch", ylabel = "accuracy")
plt.legend()
```




    <matplotlib.legend.Legend at 0x7f5a06ef06d0>




    
![BP5_6]({{ site.baseurl }}/images/BP5_6.png)
    


As is evident, this model performed much better than our previous models.\ 
This model had a validation accuracy between **95.5% and 97%** which is is great. Clearly, there is no overfitting as we performed better on the validation set than on the training set.\ 
These results are good enough for us to now try it on our hidden test data.\


# Test Data Score #


```python
model4.evaluate(test_dataset,verbose=2)
```

    6/6 - 1s - loss: 0.0989 - accuracy: 0.9635 - 711ms/epoch - 119ms/step
    




    [0.09890711307525635, 0.9635416865348816]



Those are some pretty impressive scores.\
Soon, we'll have game shows such as "Are you smarter than a 5th grader's machine learning project". Rolls right off the tongue.\
Overall, these results are amazing and our model can accurately tell the difference between a dog and a cat. Just don't throw a horse or something in there.
